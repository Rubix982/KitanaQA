{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training using the ALUM algorithm overrides the usual training step method to generate the adversarial loss alongside the normal loss. Here, we demonstrate how to perform adversarial training and then evaluate using the primitive trainer class. Then, we show how this can be integrated into an automated pipeline using Flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dummy train and test data from package\n",
    "TRAIN_PATH = pkg_resources.resource_filename(\n",
    "            'doggmentator', 'support/unittest-squad.json')\n",
    "EVAL_PATH = pkg_resources.resource_filename(\n",
    "            'doggmentator', 'support/unittest-squad.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doggmentator.trainer.run_pipeline import _setup\n",
    "hparams = {\n",
    "            \"model_type\" : \"distilbert\",\n",
    "            \"model_name_or_path\" : \"distilbert-base-uncased\",\n",
    "            \"output_dir\" : \"./example_outputs\",\n",
    "            \"cache_dir\" : \"./example_outputs\",\n",
    "            \"data_dir\" : \"./example_outputs\",\n",
    "            \"train_file_path\" : TRAIN_PATH,\n",
    "            \"predict_file_path\" : {\"dev-v1.1\": EVAL_PATH},\n",
    "            \"aug_file_path\" : None,\n",
    "            \"do_aug\" : False,\n",
    "            \"do_alum\" : True,\n",
    "            \"alpha\" : 5,\n",
    "            \"eps\" : 1e-4,\n",
    "            \"eta\" : 1e-5,\n",
    "            \"sigma\" : 1e-3,\n",
    "            \"do_train\" : True,\n",
    "            \"do_eval\" : True,\n",
    "            \"per_device_train_batch_size\" : 2,\n",
    "            \"per_device_eval_batch_size\" : 1,\n",
    "            \"gradient_accumulation_steps\" : 2,\n",
    "            \"eval_all_checkpoints\" : False,\n",
    "            \"num_train_epochs\" : 1,\n",
    "            \"max_steps\" : -1,\n",
    "            \"save_steps\" : 1,\n",
    "            \"seed\" : 512,\n",
    "            \"fp16\" : False\n",
    "}\n",
    "# Initialize args\n",
    "parser = HfArgumentParser(dataclass_types=[ModelArguments, TrainingArguments])\n",
    "model_args, training_args = parser.parse_json_file(config_path)\n",
    "model, tokenizer, train_dataset = _setup(model_args, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a Flow pipeline consisting of a parent step (alum training) conditionally followed by a child step (evaluation)\n",
    "f = build_flow(\n",
    "            (model_args, training_args),\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            train_dataset=train_dataset)\n",
    "if f:\n",
    "    f.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
